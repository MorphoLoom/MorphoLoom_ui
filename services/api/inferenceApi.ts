import {apiClient} from './apiClient';
import {logger} from '../../utils/logger';
import axios from 'axios';
import type {
  InferenceRequest,
  InferenceStatusResponse,
} from '../../types/api';

/**
 * AI ì¶”ë¡  ì‹¤í–‰ ë° ë¹„ë””ì˜¤ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
 * POST /api/v1/inference/execute
 *
 * Response Codes:
 * - 200: ì„±ê³µ - ë¹„ë””ì˜¤ íŒŒì¼ ë°˜í™˜
 * - 400: íŒŒë¼ë¯¸í„° ì˜¤ë¥˜
 * - 500: ì„œë²„/ì»¨í…Œì´ë„ˆ ì‹¤í–‰ ì‹¤íŒ¨
 *
 * NOTE: react-native-fs ë¼ì´ë¸ŒëŸ¬ë¦¬ í•„ìš”
 * ì„¤ì¹˜: npm install react-native-fs
 */
export const executeInference = async (
  request: InferenceRequest,
  signal?: AbortSignal,
): Promise<InferenceStatusResponse> => {
  const requestBody: InferenceRequest = {
    ...request,
  };

  try {
    logger.log('ğŸ¬ Starting inference...');
    logger.log('ğŸ“¦ Request body:', requestBody);

    // POST ìš”ì²­ìœ¼ë¡œ ì¶”ë¡  ì‹¤í–‰ (JSON ì‘ë‹µ ë°›ê¸°)
    const response = await apiClient.post('/inference/execute', requestBody, {
      timeout: 600000, // 10ë¶„ (ì¶”ë¡  ì™„ë£Œê¹Œì§€ ëŒ€ê¸°)
      signal,
    });

    logger.log('âœ… Inference response:', response.data);

    // ì‘ë‹µ ê²€ì¦
    if (!response.data.success || !response.data.videoUrl) {
      throw new Error(response.data.error || 'ë¹„ë””ì˜¤ URLì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤');
    }

    const {videoUrl, thumbnailUrl, message} = response.data;
    logger.log('ğŸ“¥ Video URL:', videoUrl);
    logger.log('ğŸ–¼ï¸ Thumbnail URL:', thumbnailUrl);

    // ì„œë²„ì˜ videoUrlì„ ê·¸ëŒ€ë¡œ ë°˜í™˜ (ë‹¤ìš´ë¡œë“œ ì—†ì´)
    return {
      success: true,
      message: message || 'ì˜ìƒ í•©ì„± ì™„ë£Œ',
      resultVideoPath: videoUrl, // ì„œë²„ URL ê·¸ëŒ€ë¡œ ì‚¬ìš©
      thumbnailUrl,
    };
  } catch (error: any) {
    if (axios.isCancel(error)) {
      throw error;
    }
    logger.error('âŒ executeInference error:', error);
    logger.error('Error response:', error.response?.data);

    return {
      success: false,
      message: 'ì˜ìƒ í•©ì„± ì‹¤íŒ¨',
      error: error.response?.data?.error || error.message || 'ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤',
    };
  }
};

/**
 * AI ì¶”ë¡  ìƒíƒœ í™•ì¸
 * GET /api/v1/inference/status
 *
 * Response Codes:
 * - 200: ì„œë¹„ìŠ¤ ì •ìƒ
 * - 503: ì‚¬ìš© ë¶ˆê°€
 */
export const getInferenceStatus =
  async (): Promise<InferenceStatusResponse> => {
    try {
      const response = await apiClient.get('/inference/status');
      return response.data;
    } catch (error: any) {
      logger.error('getInferenceStatus error:', error);
      return {
        success: false,
        message: 'ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨',
        error: error.message,
      };
    }
  };
